{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (2.0.35)\n",
      "Requirement already satisfied: psycopg2 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (2.9.9)\n",
      "Requirement already satisfied: feedparser in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (6.0.11)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from sqlalchemy) (3.1.1)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from feedparser) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy psycopg2 feedparser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satya\\AppData\\Local\\Temp\\ipykernel_20468\\856493207.py:6: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connected and table created successfully!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, Column, String, Integer, DateTime\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Define the base class\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define the news_articles table\n",
    "class NewsArticle(Base):\n",
    "    __tablename__ = 'news_articles'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    title = Column(String, nullable=False)\n",
    "    content = Column(String)\n",
    "    publication_date = Column(DateTime)\n",
    "    source_url = Column(String, unique=True, nullable=False)\n",
    "    category = Column(String, nullable=False)\n",
    "\n",
    "# Correct password encoding for special characters in the password\n",
    "DATABASE_URL = 'postgresql://postgres:Saty%402677sa@localhost:5432/news_db'\n",
    "\n",
    "# Create an engine that connects to the PostgreSQL database\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Create the table in the database (if it doesn't already exist)\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# Set up a session to interact with the database\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "print(\"Database connected and table created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connected and table created successfully!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, Column, String, Integer, DateTime\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker  # Updated import\n",
    "\n",
    "# Define the base class\n",
    "Base = declarative_base()  # No longer using sqlalchemy.ext.declarative\n",
    "\n",
    "# Define the news_articles table\n",
    "class NewsArticle(Base):\n",
    "    __tablename__ = 'news_articles'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    title = Column(String, nullable=False)\n",
    "    content = Column(String)\n",
    "    publication_date = Column(DateTime)\n",
    "    source_url = Column(String, unique=True, nullable=False)\n",
    "    category = Column(String, nullable=False)\n",
    "\n",
    "# Define your database connection URL (make sure to use your password)\n",
    "DATABASE_URL = 'postgresql://postgres:Saty%402677sa@localhost:5432/news_db'\n",
    "\n",
    "# Create an engine that connects to the PostgreSQL database\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Create the table in the database (if it doesn't already exist)\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# Set up a session to interact with the database\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "print(\"Database connected and table created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article with URL 'https://example.com/sample-article-1' already exists in the database.\n",
      "Article with URL 'https://example.com/sample-article-2' already exists in the database.\n",
      "Article with URL 'https://example.com/sample-article-3' already exists in the database.\n",
      "All articles committed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satya\\AppData\\Local\\Temp\\ipykernel_20468\\3012307821.py:4: SAWarning: Session's state has been changed on a non-active transaction - this state will be discarded.\n",
      "  session.rollback()\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Rollback any previous transactions to ensure the session is clean\n",
    "session.rollback()\n",
    "\n",
    "# List of sample news articles\n",
    "sample_articles = [\n",
    "    {\n",
    "        \"title\": \"Sample News Article 1\",\n",
    "        \"content\": \"This is a summary of the first sample news article.\",\n",
    "        \"publication_date\": datetime.now(),\n",
    "        \"source_url\": \"https://example.com/sample-article-1\",\n",
    "        \"category\": \"Others\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Sample News Article 2\",\n",
    "        \"content\": \"This is a summary of the second sample news article.\",\n",
    "        \"publication_date\": datetime.now(),\n",
    "        \"source_url\": \"https://example.com/sample-article-2\",\n",
    "        \"category\": \"Positive/Uplifting\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Sample News Article 3\",\n",
    "        \"content\": \"This is a summary of the third sample news article.\",\n",
    "        \"publication_date\": datetime.now(),\n",
    "        \"source_url\": \"https://example.com/sample-article-3\",\n",
    "        \"category\": \"Natural Disasters\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Insert each sample article into the database after checking for duplicates\n",
    "for article in sample_articles:\n",
    "    try:\n",
    "        # Check if the article with the same source_url already exists\n",
    "        existing_article = session.query(NewsArticle).filter_by(source_url=article['source_url']).first()\n",
    "        \n",
    "        if existing_article is None:  # If no article with the same URL exists, insert it\n",
    "            new_article = NewsArticle(\n",
    "                title=article['title'],\n",
    "                content=article['content'],\n",
    "                publication_date=article['publication_date'],\n",
    "                source_url=article['source_url'],\n",
    "                category=article['category']\n",
    "            )\n",
    "            session.add(new_article)\n",
    "            print(f\"Article '{article['title']}' added successfully.\")\n",
    "        else:\n",
    "            print(f\"Article with URL '{article['source_url']}' already exists in the database.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error while inserting article '{article['title']}': {str(e)}\")\n",
    "        session.rollback()  # Rollback in case of any failure\n",
    "\n",
    "# Commit the transaction to insert the new articles\n",
    "try:\n",
    "    session.commit()\n",
    "    print(\"All articles committed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during commit: {str(e)}\")\n",
    "    session.rollback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 143 articles from RSS feeds.\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "from datetime import datetime\n",
    "\n",
    "# List of RSS feed URLs\n",
    "feed_urls = [\n",
    "    'http://rss.cnn.com/rss/cnn_topstories.rss',\n",
    "    'http://qz.com/feed',\n",
    "    'http://feeds.foxnews.com/foxnews/politics',\n",
    "    'http://feeds.reuters.com/reuters/businessNews'\n",
    "]\n",
    "\n",
    "# Function to parse RSS feeds\n",
    "def parse_feeds():\n",
    "    articles = []\n",
    "    for url in feed_urls:\n",
    "        feed = feedparser.parse(url)\n",
    "        for entry in feed.entries:\n",
    "            # Extract relevant information from each entry\n",
    "            articles.append({\n",
    "                'title': entry.title,\n",
    "                'link': entry.link,\n",
    "                'published': entry.published if 'published' in entry else datetime.now(),\n",
    "                'summary': entry.summary if 'summary' in entry else \"No summary available.\"\n",
    "            })\n",
    "    return articles\n",
    "\n",
    "# Get parsed articles from RSS feeds\n",
    "parsed_articles = parse_feeds()\n",
    "print(f\"Parsed {len(parsed_articles)} articles from RSS feeds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 143 new articles into the database.\n"
     ]
    }
   ],
   "source": [
    "# Insert parsed articles into the database\n",
    "for article in parsed_articles:\n",
    "    # Check for duplicates based on source URL\n",
    "    existing_article = session.query(NewsArticle).filter_by(source_url=article['link']).first()\n",
    "    if not existing_article:\n",
    "        new_article = NewsArticle(\n",
    "            title=article['title'],\n",
    "            content=article['summary'],\n",
    "            publication_date=datetime.now(),  # If the published date is not available\n",
    "            source_url=article['link'],\n",
    "            category=\"Uncategorized\"  # Default category, you can classify later\n",
    "        )\n",
    "        session.add(new_article)\n",
    "\n",
    "# Commit the transaction to insert the articles\n",
    "session.commit()\n",
    "\n",
    "print(f\"Inserted {len(parsed_articles)} new articles into the database.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorized 20 articles.\n"
     ]
    }
   ],
   "source": [
    "# Keywords for different categories\n",
    "category_keywords = {\n",
    "    \"Terrorism / protest / political unrest / riot\": [\"terrorism\", \"protest\", \"riot\", \"political unrest\"],\n",
    "    \"Positive/Uplifting\": [\"hope\", \"positive\", \"uplift\", \"inspiring\", \"good news\"],\n",
    "    \"Natural Disasters\": [\"earthquake\", \"flood\", \"hurricane\", \"disaster\", \"tornado\"]\n",
    "}\n",
    "\n",
    "# Function to categorize an article based on keywords\n",
    "def categorize_article(content):\n",
    "    for category, keywords in category_keywords.items():\n",
    "        if any(keyword in content.lower() for keyword in keywords):\n",
    "            return category\n",
    "    return \"Others\"  # Default category if no keywords match\n",
    "\n",
    "# Fetch all uncategorized articles from the database\n",
    "uncategorized_articles = session.query(NewsArticle).filter_by(category=\"Uncategorized\").all()\n",
    "\n",
    "# Categorize each article\n",
    "for article in uncategorized_articles:\n",
    "    article.category = categorize_article(article.content)\n",
    "    session.add(article)  # Update the article with the new category\n",
    "\n",
    "# Commit the changes to the database\n",
    "session.commit()\n",
    "\n",
    "print(f\"Categorized {len(uncategorized_articles)} articles.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Natural Disasters, Count: 9\n",
      "Category: Others, Count: 152\n",
      "Category: Positive/Uplifting, Count: 4\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import func\n",
    "\n",
    "# Count the number of articles in each category\n",
    "category_counts = session.query(NewsArticle.category, func.count(NewsArticle.id)).group_by(NewsArticle.category).all()\n",
    "\n",
    "for category, count in category_counts:\n",
    "    print(f\"Category: {category}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Sample News Article 3, URL: https://example.com/sample-article-3\n",
      "Title: Biden undermines Harris claim that Ron DeSantis is politicizing hurricane response: 'Doing a great job', URL: https://www.foxnews.com/politics/biden-undermines-harris-claim-ron-desantis-politicizing-hurricane-response-doing-great-job\n",
      "Title: North Carolina residents will see changes to early voting after Hurricane Helene, URL: https://www.foxnews.com/politics/north-carolina-residents-see-changes-early-voting-after-hurricane-helene\n",
      "Title: Here are all the airports closing down ahead of Hurricane Milton, URL: https://qz.com/hurricane-milton-airport-closures-orlando-tampa-1851667895\n",
      "Title: Boeing is restarting talks to end a strike some compare to an economic Hurricane Helene, URL: https://qz.com/boeing-strike-negotiations-act-of-god-1851666732\n",
      "Title: Red Lobster's new CEO admits it: 'Endless Shrimp' was a disaster, URL: https://qz.com/red-lobster-ceo-endless-shrimp-disaster-1851666647\n",
      "Title: Biden cancels overseas trip as Milton bears down on Florida; DeSantis tells VP 'it's not about you Kamala', URL: https://www.foxnews.com/politics/biden-cancels-overseas-trip-milton-bears-down-florida-desantis-tells-vp-its-not-about-you-kamala\n",
      "Title: Mayorkas rips 'politicized' atmosphere over FEMA disaster response amid GOP criticism: 'It sows distrust', URL: https://www.foxnews.com/politics/mayorkas-rips-politicized-atmosphere-over-fema-disaster-response-amid-gop-criticism-it-sows-distrust\n",
      "Title: Eye of the Storm: Back-to-back hurricanes threaten to upend Harris-Trump presidential showdown, URL: https://www.foxnews.com/politics/eye-storm-hurricanes-theaten-upend-harris-trump-presidential-showdown\n"
     ]
    }
   ],
   "source": [
    "# Fetch articles in the 'Natural Disasters' category\n",
    "natural_disasters_articles = session.query(NewsArticle).filter_by(category=\"Natural Disasters\").all()\n",
    "\n",
    "for article in natural_disasters_articles:\n",
    "    print(f\"Title: {article.title}, URL: {article.source_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (3.0.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from flask) (3.0.4)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from flask) (1.8.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "pip install flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask-sqlalchemy in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (3.1.1)\n",
      "Requirement already satisfied: flask>=2.2.5 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from flask-sqlalchemy) (3.0.3)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.16 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from flask-sqlalchemy) (2.0.35)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from flask>=2.2.5->flask-sqlalchemy) (3.0.4)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from flask>=2.2.5->flask-sqlalchemy) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from flask>=2.2.5->flask-sqlalchemy) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from flask>=2.2.5->flask-sqlalchemy) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from flask>=2.2.5->flask-sqlalchemy) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from sqlalchemy>=2.0.16->flask-sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from sqlalchemy>=2.0.16->flask-sqlalchemy) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.1.3->flask>=2.2.5->flask-sqlalchemy) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (from Jinja2>=3.1.2->flask>=2.2.5->flask-sqlalchemy) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask-sqlalchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\satya\\appdata\\roaming\\python\\python312\\site-packages (2.9.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Article Aggregator\n",
    "\n",
    "## Project Description\n",
    "\n",
    "This project is a **News Article Aggregator** that collects news articles from various RSS feeds, stores them in a database, and categorizes them into predefined categories. It is designed to process articles asynchronously using Celery, with text classification handled via Natural Language Processing (NLP).\n",
    "\n",
    "### Features:\n",
    "- Collects news from multiple RSS feeds.\n",
    "- Categorizes news articles into the following categories:\n",
    "  - Terrorism/Protest/Political Unrest/Riot\n",
    "  - Positive/Uplifting News\n",
    "  - Natural Disasters\n",
    "  - Others\n",
    "- Stores the articles in a PostgreSQL database.\n",
    "- Uses Celery for task queue management, ensuring the app can handle large amounts of incoming news articles efficiently.\n",
    "- Simple Flask interface to view and manage the parsed news.\n",
    "\n",
    "## Project Structure\n",
    "\n",
    "```plaintext\n",
    "├── app.py                  # Main application file to run the Flask server\n",
    "├── feed_parser.py           # Script to parse RSS feeds\n",
    "├── tasks.py                 # Celery tasks to manage asynchronous processing\n",
    "├── models.py                # Database models and schema\n",
    "├── requirements.txt         # Python dependencies needed for the project\n",
    "└── README.md                # Project documentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technologies Used\n",
    "\n",
    "- **Programming Language**: Python\n",
    "- **Libraries**: pandas, numpy, matplotlib, scikit-learn\n",
    "- **Framework**: Flask (for web server)\n",
    "- **Database**: PostgreSQL\n",
    "- **Task Queue**: Celery\n",
    "- **NLP Libraries**: NLTK or spaCy for categorizing news articles\n",
    "- **RSS Parsing**: Feedparser\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
